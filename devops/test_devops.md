# Test Technique â€“ DevOps (Sans serveur rÃ©el)

## ğŸ¯ Objectif
Ã‰valuer la capacitÃ© du candidat Ã  automatiser build, tests, packaging, dÃ©ploiement simulÃ© et monitoring sans accÃ¨s Ã  des serveurs persistants. L'accent est mis sur la qualitÃ© des pipelines, la sÃ©curitÃ© des secrets, l'observabilitÃ© et la capacitÃ© Ã  produire une documentation reproductible.

---

## ğŸš© Contexte
Tu dois prendre un projet "starter" (fourni) et construire une **chaÃ®ne CI/CD** automatisÃ©e, des artefacts dockerisÃ©s, une stratÃ©gie de dÃ©ploiement simulÃ© et une couche d'observabilitÃ©. Tout doit Ãªtre exÃ©cutable dans un environnement local ou sur des environnements Ã©phÃ©mÃ¨res (GitHub Actions, Gitpod, Codespaces, Railway etc.).

---

## ğŸ§© Exercice 1 â€” Dockerisation complÃ¨te
- Dockeriser l'application (multi-stage si nÃ©cessaire).
- Fournir `docker-compose.yml` qui lance :
  - app (API)
  - DB (Postgres ou MySQL)
  - reverse proxy (nginx)
  - outil de monitoring lÃ©ger (Prometheus + Grafana container, ou Netdata)
- S'assurer que :
  - Les volumes persistant sont configurÃ©s.
  - Les `.env` ne sont pas commit.
  - Un fichier `env.example` documente les variables nÃ©cessaires.

**CritÃ¨res :**
- Images lÃ©gÃ¨res et multi-stage.
- Bonne sÃ©paration des responsabilitÃ©s.
- Persistance fonctionnelle.

---

## ğŸ” Exercice 2 â€” CI (GitHub Actions)
- CrÃ©er un workflow `ci.yml` qui :
  - Lint le code
  - Lance les tests unitaires
  - Build les images Docker
  - Scanne les vulnÃ©rabilitÃ©s (ou exÃ©cute `trivy`/`act` basic check`) â€” si impossible, documenter l'approche
- Le workflow doit Ãªtre dÃ©clenchable sur PR.

**CritÃ¨res :**
- Ã‰tapes claires, jobs parallÃ©lisables.
- Gestion sÃ©curisÃ©e des secrets (documentation et usage via GitHub Secrets).

---

## ğŸš€ Exercice 3 â€” CD (simulÃ©)
Ã‰tant donnÃ© l'absence de serveurs, implÃ©mente une stratÃ©gie de **dÃ©ploiement simulÃ©** :

### Option A â€” DÃ©ploiement local "simulateur"
- Script `scripts/deploy_local.sh` qui :
  - Build les images
  - Lance `docker-compose -f deploy/docker-compose.yml up -d`
  - Copie les artefacts dans un rÃ©pertoire `deploy/releases/<timestamp>/`
  - Met Ã  jour un fichier `deploy/current -> deploy/releases/<timestamp>`
  - GÃ©nÃ¨re un manifeste `deploy/releases/<timestamp>/manifest.json` contenant metadata (tag, sha, date, job-runner)
- Fournir un script `scripts/rollback.sh` qui rÃ©tablit `deploy/current` vers la release prÃ©cÃ©dente.

### Option B â€” Environnements Ã©phÃ©mÃ¨res
- DÃ©montrer dÃ©ploiement sur un service gratuit/Ã©ducatif (GitHub Codespaces / Gitpod / Railway free tier).
- Fournir instructions pour reproduire le dÃ©ploiement.

**CritÃ¨res :**
- Automatisation reproducible
- Manifesting & atomic switch (symlink) pour simuler gradual cutover
- Rollback simple et testÃ©

---

## ğŸ“ˆ Exercice 4 â€” ObservabilitÃ© & Alerting
- Fournir un docker-compose ou instructions GitHub Actions qui dÃ©marre (ou simule) :
  - Metrics exposition (Prometheus scrape target)
  - Grafana dashboard minimal (CPU, Memory, uptime, endpoint health)
  - Logging centralisÃ© (optionnel : vector, fluentd, filebeat â†’ loki)
- DÃ©crire dans `README.md` les rÃ¨gles d'alerte critiques (ex: `error rate > X`, `latency > Yms`, `DB connections > Z`).

**CritÃ¨res :**
- Dashboard minimal fonctionnel ou instructions claires pour l'utiliser.
- Playbook de rÃ©action succinct (rollback, scaling, notification).

---

## â“ Exercice 5 â€” Questions & cas pratiques (answers.md)
RÃ©pondre dans `answers.md` (format markdown) aux questions :
1. Comment gÃ©rez-vous les secrets en production (vault vs GitHub Secrets vs env files) ? Expliquer la stratÃ©gie choisie.
2. DÃ©crire une procÃ©dure de rollback en cas de dÃ©ploiement dÃ©fectueux.
3. Comment monitoreriez-vous une augmentation soudaine du 500 Errors ?
4. Comment automatiser les migrations DB dans un pipeline sÃ»r ?

---

## ğŸ“‹ Livrables attendus
- `docker-compose.yml` + `deploy/` scripts
- `.github/workflows/ci.yml` (et `cd.yml` si pertinent)
- `README.md` avec instructions pour exÃ©cuter localement et en environnement Ã©phÃ©mÃ¨re
- `answers.md` rÃ©ponses aux questions
- PR vers le repo central / fork PR

---

## â± Temps recommandÃ©
- 6 Ã  10 heures rÃ©alistes selon expertise

---

## ğŸ“Š BarÃ¨me & CritÃ¨res d'Ã©valuation
- Dockerisation & persistance : 25%
- CI (qualitÃ© des workflows) : 30%
- Simulated CD (manifests, symlink, rollback) : 20%
- ObservabilitÃ© & alerting : 15%
- Documentation & rÃ©ponses (answers.md) : 10%

---

## ğŸš€ Soumission (Git/GitHub)
1. Fork le repo central.
2. CrÃ©e une branche `develop`.
3. Commits rÃ©guliers et pousse sur ton fork.
4. Ouvre une Pull Request vers le repo central avec le titre `[DevOps] PrÃ©nom Nom`.
5. Dans la PR, prÃ©ciser si un environnement Ã©phÃ©mÃ¨re a Ã©tÃ© utilisÃ© (Codespaces/Gitpod/Railway) et fournir les URLs.

---

### âœ… Ã‰valuation Git/GitHub (transversal)
Dans les deux tests, tu seras notÃ© aussi sur :
- QualitÃ© et granularitÃ© des commits
- Usage de branches (feature branches, PR)
- ClartÃ© du README et du PR description
- CapacitÃ© Ã  rÃ©pondre aux commentaires de code review (si interaction rÃ©elle proposÃ©e)
